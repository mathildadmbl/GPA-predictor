{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark Pipeline : Predicting a student's GPA from his performances\n",
    "DEMBELE Mathilda, MARSOT Elouan\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Starting the Spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialisation des librairies pyspark\n",
    "\n",
    "# Initialisation de Spark\n",
    "import pyspark\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# import ML pyspark modules\n",
    "# some examples\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.classification import MultilayerPerceptronClassifier\n",
    "\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "\n",
    "\n",
    "from pyspark.mllib.classification import LogisticRegressionWithLBFGS\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "from pyspark.mllib.util import MLUtils\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "\n",
    "from pyspark import SparkConf, SparkContext, SQLContext\n",
    "\n",
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"GPAPredictor\") \\\n",
    "    .getOrCreate()\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DATASET DESCRIPTION\n",
    "- TRAIN : 1531 samples \n",
    "- TEST : 384 samples \n",
    "- each line in the dataset stands for some student\n",
    "- each column is a feature of performance for the student\n",
    "\n",
    "14 features :\n",
    "- StudentID : int, a four-figures unique number \n",
    "- Age : int \n",
    "- Gender : binary, 0 for a man, 1 for a woman \n",
    "- Ethnicity : categorial (Caucasian, Asian, African American, Other)\n",
    "- ParentalEducation : categorial (High School, Bachelor, Some College, Higher)\n",
    "- StudyTimeWeekly : float, nb of hours per week \n",
    "- Absences : int \n",
    "- Tutoring : binary, 1 if yes, 0 otherwise \n",
    "- ParentalSupport : categorial (Low, Moderate, High, Very High)\n",
    "- Extracurricular : binary\n",
    "- Sports : binary \n",
    "- Music : binary \n",
    "- Volunteering : binary \n",
    "\n",
    "- GPA : float (from 0 to 4)\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "fileNameTrain = \"datasets/train.csv\"\n",
    "fileNameTest = \"datasets/test.csv\"\n",
    "\n",
    "# Reading the datasets\n",
    "train_set = spark.read.csv(fileNameTrain, header=True, inferSchema=True)\n",
    "test_set = spark.read.csv(fileNameTest, header=True, inferSchema=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- StudentID: integer (nullable = true)\n",
      " |-- Age: integer (nullable = true)\n",
      " |-- Gender: integer (nullable = true)\n",
      " |-- Ethnicity: string (nullable = true)\n",
      " |-- ParentalEducation: string (nullable = true)\n",
      " |-- StudyTimeWeekly: double (nullable = true)\n",
      " |-- Absences: integer (nullable = true)\n",
      " |-- Tutoring: integer (nullable = true)\n",
      " |-- ParentalSupport: string (nullable = true)\n",
      " |-- Extracurricular: integer (nullable = true)\n",
      " |-- Sports: integer (nullable = true)\n",
      " |-- Music: integer (nullable = true)\n",
      " |-- Volunteering: integer (nullable = true)\n",
      " |-- GPA: double (nullable = true)\n",
      "\n",
      "root\n",
      " |-- StudentID: integer (nullable = true)\n",
      " |-- Age: integer (nullable = true)\n",
      " |-- Gender: integer (nullable = true)\n",
      " |-- Ethnicity: string (nullable = true)\n",
      " |-- ParentalEducation: string (nullable = true)\n",
      " |-- StudyTimeWeekly: double (nullable = true)\n",
      " |-- Absences: integer (nullable = true)\n",
      " |-- Tutoring: integer (nullable = true)\n",
      " |-- ParentalSupport: string (nullable = true)\n",
      " |-- Extracurricular: integer (nullable = true)\n",
      " |-- Sports: integer (nullable = true)\n",
      " |-- Music: integer (nullable = true)\n",
      " |-- Volunteering: integer (nullable = true)\n",
      " |-- GPA: double (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(StudentID=2340, Age=16, Gender=1, Ethnicity='Other', ParentalEducation='Higher', StudyTimeWeekly=5.04404804318662, Absences=25, Tutoring=1, ParentalSupport='Moderate', Extracurricular=1, Sports=0, Music=0, Volunteering=0, GPA=0.886889415770466)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CHECKING THAT THEY HAVE THE SAME SCHEMA\n",
    "train_set.printSchema()\n",
    "test_set.printSchema()\n",
    "train_set.take(1)\n",
    "test_set.take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------+-----------+--------------+----------------------+--------------------+-------------+-------------+--------------------+--------------------+-----------+----------+-----------------+--------+\n",
      "|sum(StudentID)|sum(Age)|sum(Gender)|sum(Ethnicity)|sum(ParentalEducation)|sum(StudyTimeWeekly)|sum(Absences)|sum(Tutoring)|sum(ParentalSupport)|sum(Extracurricular)|sum(Sports)|sum(Music)|sum(Volunteering)|sum(GPA)|\n",
      "+--------------+--------+-----------+--------------+----------------------+--------------------+-------------+-------------+--------------------+--------------------+-----------+----------+-----------------+--------+\n",
      "|             0|       0|          0|             0|                   142|                   0|            0|            0|                 132|                   0|          0|         0|                0|       0|\n",
      "+--------------+--------+-----------+--------------+----------------------+--------------------+-------------+-------------+--------------------+--------------------+-----------+----------+-----------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Missing values\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "train_set.select([(col(c).isNull().cast(\"int\")).alias(c) for c in train_set.columns]).groupBy().sum().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "only ParentalEducation and ParentalSupport have some missing values : this should be handled in our future pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High School\n",
      "Higher\n",
      "Bachelor\n",
      "Some College\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "categories = train_set.select(\"ParentalEducation\").distinct().collect()\n",
    "for row in categories:\n",
    "    print(row[\"ParentalEducation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High\n",
      "Very High\n",
      "Low\n",
      "Moderate\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "categories = train_set.select(\"ParentalSupport\").distinct().collect()\n",
    "for row in categories:\n",
    "    print(row[\"ParentalSupport\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because there is an order among those categories, let's map them then we will try to imput them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordinal_mapping_education = {\"High School\": 1, \"Some College\": 2, \"Bachelor\": 3, \"Higher\": 4}\n",
    "ordinal_mapping_support = {\"Low\": 0, \"Moderate\": 1, \"High\": 2, \"Very High\": 4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Transformer\n",
    "from pyspark.sql.functions import when, col\n",
    "\n",
    "class OrdinalEncoder(Transformer):\n",
    "    def __init__(self, mappings, inputCols, outputCols):\n",
    "        super(OrdinalEncoder, self).__init__()\n",
    "        self.mappings = mappings  \n",
    "        self.inputCols = inputCols\n",
    "        self.outputCols = outputCols\n",
    "\n",
    "    def _transform(self, df):\n",
    "        for inputCol, outputCol, mapping in zip(self.inputCols, self.outputCols, self.mappings):\n",
    "            expr = None\n",
    "            for category, value in mapping.items():\n",
    "                if expr is None:\n",
    "                    expr = when(col(inputCol) == category, value)\n",
    "                else:\n",
    "                    expr = expr.when(col(inputCol) == category, value)\n",
    "            df = df.withColumn(outputCol, expr.otherwise(None)) \n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Imputer\n",
    "\n",
    "encoder = OrdinalEncoder(\n",
    "    mappings=[ordinal_mapping_education, ordinal_mapping_support],\n",
    "    inputCols=[\"ParentalEducation\", \"ParentalSupport\"],\n",
    "    outputCols=[\"ParentalEducation\", \"ParentalSupport\"]\n",
    ")\n",
    "\n",
    "imputer = Imputer(\n",
    "    inputCols=[\"ParentalEducation\", \"ParentalSupport\"],\n",
    "    outputCols=[\"ParentalEducation\", \"ParentalSupport\"]\n",
    ").setStrategy(\"mode\")\n",
    "\n",
    "pipeline = Pipeline(stages=[encoder, imputer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(StudentID=3321, Age=17, Gender=1, Ethnicity='Caucasian', ParentalEducation=1, StudyTimeWeekly=9.90635293867818, Absences=25, Tutoring=0, ParentalSupport=2, Extracurricular=1, Sports=1, Music=0, Volunteering=0, GPA=1.08238995034159),\n",
       " Row(StudentID=1160, Age=18, Gender=0, Ethnicity='Caucasian', ParentalEducation=1, StudyTimeWeekly=4.68115550034998, Absences=20, Tutoring=0, ParentalSupport=2, Extracurricular=0, Sports=0, Music=0, Volunteering=1, GPA=1.18954876961879),\n",
       " Row(StudentID=2644, Age=16, Gender=0, Ethnicity='Other', ParentalEducation=2, StudyTimeWeekly=6.84531185579492, Absences=13, Tutoring=0, ParentalSupport=1, Extracurricular=0, Sports=0, Music=1, Volunteering=0, GPA=1.85267174103724),\n",
       " Row(StudentID=2321, Age=18, Gender=0, Ethnicity='Asian', ParentalEducation=1, StudyTimeWeekly=19.8857597152212, Absences=2, Tutoring=0, ParentalSupport=2, Extracurricular=1, Sports=0, Music=0, Volunteering=0, GPA=3.51723712873573),\n",
       " Row(StudentID=2419, Age=15, Gender=1, Ethnicity='African American', ParentalEducation=3, StudyTimeWeekly=14.806260616879, Absences=20, Tutoring=0, ParentalSupport=4, Extracurricular=0, Sports=0, Music=0, Volunteering=0, GPA=1.58209326617451)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_model = pipeline.fit(train_set)\n",
    "df_transformed = pipeline_model.transform(train_set)\n",
    "\n",
    "df_transformed.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform the other features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_features = [\"Age\", \"StudyTimeWeekly\", \"Absences\"]\n",
    "categorical_features = [\"Ethnicity\"]\n",
    "\n",
    "# the other columns are already preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import OneHotEncoder, StandardScaler, VectorAssembler, StringIndexer\n",
    "\n",
    "# one hot \n",
    "indexer = StringIndexer(inputCol=\"Ethnicity\", outputCol=\"Ethnicity_indexed\")\n",
    "onehot_encoder= OneHotEncoder(inputCol=\"Ethnicity_indexed\", outputCol=\"Ethnicity_encoded\")\n",
    "# scaling\n",
    "numeric_assembler = VectorAssembler(inputCols=numerical_features, outputCol=\"numeric_features\")\n",
    "scaler = StandardScaler(inputCol=\"numeric_features\", outputCol=\"numeric_features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(StudentID=3321, Age=17, Gender=1, Ethnicity='Caucasian', ParentalEducation='High School', StudyTimeWeekly=9.90635293867818, Absences=25, Tutoring=0, ParentalSupport='High', Extracurricular=1, Sports=1, Music=0, Volunteering=0, GPA=1.08238995034159, Ethnicity_indexed=0.0, Ethnicity_encoded=SparseVector(3, {0: 1.0})),\n",
       " Row(StudentID=1160, Age=18, Gender=0, Ethnicity='Caucasian', ParentalEducation='High School', StudyTimeWeekly=4.68115550034998, Absences=20, Tutoring=0, ParentalSupport='High', Extracurricular=0, Sports=0, Music=0, Volunteering=1, GPA=1.18954876961879, Ethnicity_indexed=0.0, Ethnicity_encoded=SparseVector(3, {0: 1.0})),\n",
       " Row(StudentID=2644, Age=16, Gender=0, Ethnicity='Other', ParentalEducation='Some College', StudyTimeWeekly=6.84531185579492, Absences=13, Tutoring=0, ParentalSupport=None, Extracurricular=0, Sports=0, Music=1, Volunteering=0, GPA=1.85267174103724, Ethnicity_indexed=3.0, Ethnicity_encoded=SparseVector(3, {})),\n",
       " Row(StudentID=2321, Age=18, Gender=0, Ethnicity='Asian', ParentalEducation='High School', StudyTimeWeekly=19.8857597152212, Absences=2, Tutoring=0, ParentalSupport='High', Extracurricular=1, Sports=0, Music=0, Volunteering=0, GPA=3.51723712873573, Ethnicity_indexed=2.0, Ethnicity_encoded=SparseVector(3, {2: 1.0})),\n",
       " Row(StudentID=2419, Age=15, Gender=1, Ethnicity='African American', ParentalEducation='Bachelor', StudyTimeWeekly=14.806260616879, Absences=20, Tutoring=0, ParentalSupport='Very High', Extracurricular=0, Sports=0, Music=0, Volunteering=0, GPA=1.58209326617451, Ethnicity_indexed=1.0, Ethnicity_encoded=SparseVector(3, {1: 1.0}))]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = Pipeline(stages=[indexer, onehot_encoder])\n",
    "pipeline_model = pipeline.fit(train_set)\n",
    "df_transformed = pipeline_model.transform(train_set)\n",
    "\n",
    "df_transformed.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "faire une selection des colonnes dans les tp "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
